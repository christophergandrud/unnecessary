---
title: "Unnecessary Bias"
subtitle: "Do Not Use the Average of Skewed Simulation Distributions to Estimate the Quantity of Interest, Use Medians"
author: "Christopher Gandrud"
date: "12/2/2017"
output: 
    pdf_document:
        fig_width: 7
        fig_height: 3 
        fig_caption: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(gridExtra)
```

Point estimates from simulated QI distributions are effectively measures of central tendency of these distributions. It is important to use the most appropriate measure of central tendency given each distribution's characteristics.

Many QI distributions are by construction asymmetric, being skewed and/or bounded (e.g. by 0 and 1 for predicted probabilities). As in any other context, when summarising the central tendency of such distributions the median is a more accurate measure of central tendency than the mean.

Choosing to use the mean rather than median to summarise a skewed simulated QI distribution produces biased point estimates compared to the equivalent maximum likelihood estimates. Rainey (work in progress, 4-5) shows the effect of taking simulation distribution averages for QIs from a probit regression. Figure 1 shows the distribution of simulated predicted probabilities from one of the simulated probit regressions. This is a highly skewed distribution for which the mean would be an inappropriate measure of central tendency, especially compared to the median.

```{r, echo=FALSE, message=FALSE, cache=TRUE, fig.height=4, fig.width=4}
n <- 100
x <- rnorm(n)

n_qi <- 100
x0 <- seq(-3, 3, length.out = n_qi)

beta <- c(-2, 1)
lambda <- exp(beta[1] + beta[2]*x)

n_sims <- 1000

# MEAN -------------------------------------------------------------------------
tau_hat_mle <- tau_hat_avg <- matrix(NA, nrow = n_sims, ncol = n_qi)
for (i in 1:n_sims) {
  y <- rpois(n, lambda = lambda)
  fit <- glm(y ~ x, family = poisson)
  beta_hat <- coef(fit)
  Sigma_hat <- vcov(fit)
  beta_tilde <- MASS::mvrnorm(1000, mu = beta_hat, Sigma = Sigma_hat)
  tau_tilde <- t(exp(cbind(1, x0)%*%t(beta_tilde)))*beta_tilde[, 2]
  tau_hat_avg[i, ] <- apply(tau_tilde, 2, mean)
  tau_hat_mle[i, ] <- exp(beta_hat[1] + beta_hat[2]*x0)*beta_hat[2]
}

hist(tau_tilde[, 2])
```

Rainey (work in progress, 4-5) shows how finding point estimates from such distributions using their means increases bias compared to the maximum likelihood (ML) point estimates (Figure 2, left-panel). Using the simulated QI distributions' medians instead (Figure 2, right-panel) matches the performance of the MLE approach.


```{r, echo=FALSE, message=FALSE, cache=TRUE}
sims_df <- data.frame(true_qi = exp(beta[1] + beta[2]*x0)*beta[2],
                      mle = apply(tau_hat_mle, 2, mean),
                      avg = apply(tau_hat_avg, 2, mean)) %>%
  gather(method, ev, mle, avg)

p_mean <- ggplot(sims_df, aes(x = true_qi, y = ev - true_qi, linetype = method)) +
  geom_line() +
  theme_bw() +
  labs(title = "Simmulation Average",
       x = "True Marginal Effect",
       y = "Bias in Estimates of ME",
       linetype = "Method")

# MEDIAN -------------------------------------------------------------------------
tau_hat_mle <- tau_hat_median <- matrix(NA, nrow = n_sims, ncol = n_qi)
for (i in 1:n_sims) {
  y <- rpois(n, lambda = lambda)
  fit <- glm(y ~ x, family = poisson)
  beta_hat <- coef(fit)
  Sigma_hat <- vcov(fit)
  beta_tilde <- MASS::mvrnorm(1000, mu = beta_hat, Sigma = Sigma_hat)
  tau_tilde <- t(exp(cbind(1, x0)%*%t(beta_tilde)))*beta_tilde[, 2]
  tau_hat_median[i, ] <- apply(tau_tilde, 2, median)
  tau_hat_mle[i, ] <- exp(beta_hat[1] + beta_hat[2]*x0)*beta_hat[2]
}

sims_df <- data.frame(true_qi = exp(beta[1] + beta[2]*x0)*beta[2],
                      mle = apply(tau_hat_mle, 2, mean),
                      median = apply(tau_hat_median, 2, mean)) %>%
  gather(method, ev, mle, median)

p_median <- ggplot(sims_df, aes(x = true_qi, y = ev - true_qi, linetype = method)) +
  geom_line() +
  theme_bw() +
  labs(title = "Simulation Median",
       x = "True Marginal Effect",
       y = "Bias in Estimates of ME",
       linetype = "Method")

grid.arrange(p_mean, p_median, ncol = 2)

```

```{r setup_histogram, echo=FALSE, message=FALSE, warning=FALSE}
# load data
ge <- read_csv("data/ge.csv")

# drop missing
keep <- c("court", "dq", "cr", "pc", "ag", "sp", "pe", "cc", "ap", "dc", "st", "sg")
ge <- na.omit(ge[, keep])

# formula
f <- court ~ dq + cr + pc + ag + sp + pe + cc + ap + dc + st + sg

# estimate models
fit <- glm(f, data = ge, family = binomial(link = "probit"))

# predicted probability
beta_hat <- coef(fit)
Sigma_hat <- vcov(fit)
beta_tilde <- MASS::mvrnorm(10000, mu = beta_hat, Sigma = Sigma_hat)
X_c <- cbind(1, as.matrix(select(ge, -court)))
tau_tilde <- t(pnorm(X_c%*%t(beta_tilde)))
```

Similarly, in Rainey's replication example, using the median rather than the mean produces QI point estimates almost identical to MLE (Figures 3 and 4).

```{r message=FALSE, echo=FALSE}
tau_hat_median <- apply(tau_tilde, 2, median)  # simulation median

tau_hat_mle <- pnorm(X_c%*%beta_hat)  # mle

tau_df <- data.frame(mle = tau_hat_mle,
                     median = tau_hat_median)
ggplot(tau_df, aes(x = tau_hat_mle, tau_hat_median)) +
  scale_color_gradient2(mid = "black", low = "blue", high = "red") +
  geom_point(shape = 21) +
  geom_abline(intercept = 0, slope = 1) +
  theme_bw() +
  labs(title = "Probability of a Conservative Decision",
       x = "Maximum Likelihood Estimate",
       y = "Simulation Estimate (median)")
```

```{r message=FALSE, echo=FALSE}
# first difference for sg
X_lo <- X_hi <- X_c
X_lo[, "sg"] <- 0
X_hi[, "sg"] <- 1

tau_tilde_hi <- t(pnorm(X_hi%*%t(beta_tilde)))
tau_hat_hi_median <- apply(tau_tilde_hi, 2, median) # simulation medians

tau_tilde_lo <-  t(pnorm(X_lo%*%t(beta_tilde)))
tau_hat_lo_median <- apply(tau_tilde_lo, 2, median) # simulation medians

tau_hat_median <- tau_hat_hi_median - tau_hat_lo_median

tau_hat_mle <- pnorm(X_hi%*%beta_hat) - pnorm(X_lo%*%beta_hat)  # mle

tau_df <- data.frame(mle = tau_hat_mle,
                     median = tau_hat_median)

ggplot(tau_df, aes(x = tau_hat_mle, tau_hat_median)) +
  geom_point(shape = 21) +
  geom_abline(intercept = 0, slope = 1) +
  theme_bw() +
  labs(title = "Effect of a Solicitor General Brief",
       x = "Maximum Likelihood Estimate",
       y = "Simulation Estimate (median)")
```

The QI in the latter example is the first difference of the predicted probabilities. Here we can begin to see some hint at what Rainey calls "transformation bias" (i.e. there is a slight difference in the simulation median and MLE approaches). First differences are produced by taking the difference of two predicted probabilities, i.e. an extra transformation. As such the transformation bias grows. However, when we use the appropriate measure of the QI simulated distributions' central tendency--median--the bias is very small and likely not substantively meaningful.

# Key take away

Each simulated quantity of interest's distribution needs to be summarised using the appropriate summary statistics for the shape of its distribution. If inappropriate statistics are used, we can expect unnecessarily biased summaries.

Many quantity of interests' distributions are far from normal. Many are bounded and exhibit bunching close to the bounds, as for predicted probabilities. In these cases medians can be useful rather than means. These types of distributions may even be poorly served not only in the summary of their central tendency but their range. Typically researchers use central simulation distribution intervals (e.g. the 95% central interval) to find uncertainty bounds. However, these can be biased in the same way as means are for skewed and bounded distributions. In these cases, summary tools such as the highest probability density regions (for a summary see [Gandrud (2015, 6)](https://www.jstatsoft.org/article/view/v065i03)) can give a more accurate perspective on the shape of the simulated distribution and thus our uncertainty about our estimates.

